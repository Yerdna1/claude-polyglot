# LiteLLM Proxy Configuration for Claude Code Multi-Provider
# This translates Anthropic API format to various providers

model_list:
  # GLM Models (Z.AI) - OpenAI-compatible
  - model_name: glm-5
    litellm_params:
      model: openai/glm-5
      api_key: os.environ/GLM_API_KEY
      api_base: https://api.z.ai/api/paas/v4

  # DeepSeek Models
  - model_name: deepseek-chat
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: os.environ/DEEPSEEK_API_KEY

  - model_name: deepseek-reasoner
    litellm_params:
      model: deepseek/deepseek-reasoner
      api_key: os.environ/DEEPSEEK_API_KEY

  # Qwen Models (Alibaba) - aliases auto-route to latest Qwen3
  - model_name: qwen-max
    litellm_params:
      model: qwen/qwen-max
      api_key: os.environ/QWEN_API_KEY

  - model_name: qwen-plus
    litellm_params:
      model: qwen/qwen-plus
      api_key: os.environ/QWEN_API_KEY

  - model_name: qwen-turbo
    litellm_params:
      model: qwen/qwen-turbo
      api_key: os.environ/QWEN_API_KEY

  # MiniMax Models
  - model_name: minimax-m2.1
    litellm_params:
      model: minimax/MiniMax-M2.1
      api_key: os.environ/MINIMAX_API_KEY

  # OpenRouter Models
  - model_name: claude-sonnet-4-5-20250929
    litellm_params:
      model: openrouter/openrouter/pony-alpha
      api_key: os.environ/OPENROUTER_API_KEY
      api_base: https://openrouter.ai/api/v1

# General settings
litellm_settings:
  drop_params: true
  set_verbose: false
